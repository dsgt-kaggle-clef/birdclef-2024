{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:31:03.538813: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-10 11:31:03.585998: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-10 11:31:03.586039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-10 11:31:03.587333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-10 11:31:03.595001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 11:31:04.639115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-10 11:31:06.542201: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "path = \"https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/TensorFlow2/variations/bird-vocalization-classifier/versions/4\"\n",
    "model = hub.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable_child',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_checkpoint_dependencies',\n",
       " '_copy_trackable_to_cpu',\n",
       " '_deferred_dependencies',\n",
       " '_delete_tracking',\n",
       " '_deserialization_dependencies',\n",
       " '_deserialize_from_proto',\n",
       " '_export_to_saved_model_graph',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_handle_deferred_dependencies',\n",
       " '_is_hub_module_v1',\n",
       " '_lookup_dependency',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_tensors',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_serialize_to_proto',\n",
       " '_serialize_to_tensors',\n",
       " '_setattr_tracking',\n",
       " '_structured_variables',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_trackable_children',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variables',\n",
       " 'graph_debug_info',\n",
       " 'infer_tf',\n",
       " 'signatures',\n",
       " 'tensorflow_git_version',\n",
       " 'tensorflow_version']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serving_default']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.signatures.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'inputs:0' shape=(None, 160000) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures[\"serving_default\"]\n",
    "model.signatures[\"serving_default\"].inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpConversionFailure",
     "evalue": "Check 'is_conversion_successful' failed at src/frontends/tensorflow/src/frontend.cpp:480:\nFrontEnd API failed with OpConversionFailure:\n[TensorFlow Frontend] Internal error, conversion is failed for ComplexAbs operation with a message:\nCheck 'complex_type_mark' failed at src/frontends/tensorflow_common/src/op/complex_abs.cpp:30:\nFrontEnd API failed with OpValidationFailureWhile validating node 'ComplexAbs':\n[TensorFlow Frontend] internal error: ComplexTypeMark is not set to input of ComplexAbs\n\n[TensorFlow Frontend] Internal error, conversion is failed for Mul operation with a message:\nCheck 'complex_type_mark_lhs != nullptr && complex_type_mark_rhs != nullptr' failed at src/frontends/tensorflow_common/src/op/binary_op.cpp:104:\nFrontEnd API failed with GeneralFailure:\nMul gox complex and non-complex inputs. Inputs should be of same type.\n\n[TensorFlow Frontend] Internal error, no translator found for operation(s): ComplexTypeMark\nTo facilitate the conversion of unsupported operations, refer to Frontend Extension documentation: https://docs.openvino.ai/latest/openvino_docs_Extensibility_UG_Frontend_Extensions.html \n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpConversionFailure\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mov\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/convert.py:100\u001b[0m, in \u001b[0;36mconvert_model\u001b[0;34m(input_model, input, output, example_input, extension, verbose, share_weights)\u001b[0m\n\u001b[1;32m     98\u001b[0m logger_state \u001b[38;5;241m=\u001b[39m get_logger_state()\n\u001b[1;32m     99\u001b[0m cli_parser \u001b[38;5;241m=\u001b[39m get_all_cli_parser()\n\u001b[0;32m--> 100\u001b[0m ov_model, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcli_parser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m restore_logger_state(logger_state)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ov_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/convert_impl.py:547\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(cli_parser, args, python_api_used)\u001b[0m\n\u001b[1;32m    545\u001b[0m send_conversion_result(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m python_api_used:\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, argv\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/convert_impl.py:489\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(cli_parser, args, python_api_used)\u001b[0m\n\u001b[1;32m    485\u001b[0m argv\u001b[38;5;241m.\u001b[39mis_python_api_used \u001b[38;5;241m=\u001b[39m python_api_used\n\u001b[1;32m    487\u001b[0m argv\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m model_framework\n\u001b[0;32m--> 489\u001b[0m ov_model \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconversion_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_default_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inp_model_is_object \u001b[38;5;129;01mand\u001b[39;00m model_framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paddle_runtime_converter:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/convert_impl.py:240\u001b[0m, in \u001b[0;36mdriver\u001b[0;34m(argv, non_default_params)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Log dictionary with non-default cli parameters where complex classes are excluded.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mstr\u001b[39m(non_default_params))\n\u001b[0;32m--> 240\u001b[0m ov_model \u001b[38;5;241m=\u001b[39m moc_emit_ir(\u001b[43mprepare_ir\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m, argv)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ov_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/convert_impl.py:189\u001b[0m, in \u001b[0;36mprepare_ir\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m extension \u001b[38;5;129;01min\u001b[39;00m filtered_extensions(argv\u001b[38;5;241m.\u001b[39mextension):\n\u001b[1;32m    188\u001b[0m             moc_front_end\u001b[38;5;241m.\u001b[39madd_extension(extension)\n\u001b[0;32m--> 189\u001b[0m     ov_model \u001b[38;5;241m=\u001b[39m \u001b[43mmoc_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoc_front_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ov_model\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m argv\u001b[38;5;241m.\u001b[39minput_model:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/tools/ovc/moc_frontend/pipeline.py:244\u001b[0m, in \u001b[0;36mmoc_pipeline\u001b[0;34m(argv, moc_front_end)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape_to_array\u001b[39m(shape: PartialShape):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [shape\u001b[38;5;241m.\u001b[39mget_dimension(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(shape\u001b[38;5;241m.\u001b[39mrank\u001b[38;5;241m.\u001b[39mget_length())]\n\u001b[0;32m--> 244\u001b[0m ov_model \u001b[38;5;241m=\u001b[39m \u001b[43mmoc_front_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ov_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/openvino/frontend/frontend.py:18\u001b[0m, in \u001b[0;36mFrontEnd.convert\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Union[Model, InputModel]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:\n\u001b[0;32m---> 18\u001b[0m     converted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, InputModel):\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Model(converted_model)\n",
      "\u001b[0;31mOpConversionFailure\u001b[0m: Check 'is_conversion_successful' failed at src/frontends/tensorflow/src/frontend.cpp:480:\nFrontEnd API failed with OpConversionFailure:\n[TensorFlow Frontend] Internal error, conversion is failed for ComplexAbs operation with a message:\nCheck 'complex_type_mark' failed at src/frontends/tensorflow_common/src/op/complex_abs.cpp:30:\nFrontEnd API failed with OpValidationFailureWhile validating node 'ComplexAbs':\n[TensorFlow Frontend] internal error: ComplexTypeMark is not set to input of ComplexAbs\n\n[TensorFlow Frontend] Internal error, conversion is failed for Mul operation with a message:\nCheck 'complex_type_mark_lhs != nullptr && complex_type_mark_rhs != nullptr' failed at src/frontends/tensorflow_common/src/op/binary_op.cpp:104:\nFrontEnd API failed with GeneralFailure:\nMul gox complex and non-complex inputs. Inputs should be of same type.\n\n[TensorFlow Frontend] Internal error, no translator found for operation(s): ComplexTypeMark\nTo facilitate the conversion of unsupported operations, refer to Frontend Extension documentation: https://docs.openvino.ai/latest/openvino_docs_Extensibility_UG_Frontend_Extensions.html \n\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "ov.convert_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 02:30:35.898243: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-06-10 02:30:35.898433: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-06-10 02:30:41.607296: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-06-10 02:30:41.607445: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-06-10 02:30:47.540835: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "ERROR:tf2onnx.tfonnx:Failed to convert node 'jax2tf_infer_fn_/TaxonomyModel/frontend/pjit_fft_/rfft' (fct=<bound method RFFTOp.version_13 of <class 'tf2onnx.onnx_opset.signal.RFFTOp'>>)\n",
      "'OP=RFFT\\nName=jax2tf_infer_fn_/TaxonomyModel/frontend/pjit_fft_/rfft\\nInputs:\\n\\tjax2tf_infer_fn_/TaxonomyModel/frontend/pjit__pad_/PadV2_9:0=Pad, [-1, 501, 1024], 1\\n\\tjax2tf_infer_fn_/TaxonomyModel/frontend/pjit_fft_/rfft/fft_length:0=Const, [1], 6\\nOutpus:\\n\\tjax2tf_infer_fn_/TaxonomyModel/frontend/pjit_fft_/rfft:0=[-1, 501, 513], 14'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/tfonnx.py\", line 292, in tensorflow_onnx_mapping\n",
      "    func(g, node, **kwargs, initialized_tables=initialized_tables, dequantize=dequantize)\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/onnx_opset/signal.py\", line 359, in version_13\n",
      "    return cls.any_version(True, 13, ctx, node, **kwargs)\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/onnx_opset/signal.py\", line 118, in any_version\n",
      "    utils.make_sure(\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/utils.py\", line 303, in make_sure\n",
      "    raise ValueError(\"make_sure failure: \" + error_msg % args)\n",
      "ValueError: make_sure failure: Current implementation of RFFT or FFT only allows ComplexAbs as consumer not {'EnsureShape'}\n",
      "ERROR:tf2onnx.tfonnx:Failed to convert node 'jax2tf_infer_fn_/TaxonomyModel/frontend/pjit_absolute_/Abs' (fct=<bound method ComplexAbsOp.version_13 of <class 'tf2onnx.onnx_opset.signal.ComplexAbsOp'>>)\n",
      "'OP=ComplexAbs\\nName=jax2tf_infer_fn_/TaxonomyModel/frontend/pjit_absolute_/Abs\\nInputs:\\n\\tjax2tf_infer_fn_/TaxonomyModel/frontend/pjit_swapaxes_/transpose:0=Transpose, [-1, 500, 513], 14\\nOutpus:\\n\\tjax2tf_infer_fn_/TaxonomyModel/frontend/pjit_absolute_/Abs:0=[-1, 500, 513], 1'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/tfonnx.py\", line 292, in tensorflow_onnx_mapping\n",
      "    func(g, node, **kwargs, initialized_tables=initialized_tables, dequantize=dequantize)\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/onnx_opset/signal.py\", line 981, in version_13\n",
      "    cls.any_version(13, ctx, node, **kwargs)\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/onnx_opset/signal.py\", line 939, in any_version\n",
      "    utils.make_sure(\n",
      "  File \"/home/anthony/.local/lib/python3.10/site-packages/tf2onnx/utils.py\", line 303, in make_sure\n",
      "    raise ValueError(\"make_sure failure: \" + error_msg % args)\n",
      "ValueError: make_sure failure: ComplexAbs expected the first dimension to be 2 but shape is [-1, 500, 513]\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient_5: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient_1: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient_3: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient_4: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [PreventGradient_2: PreventGradient] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Unsupported ops: Counter({'PreventGradient': 6})\n",
      "ERROR:tf2onnx.tfonnx:Tensorflow op [StatefulPartitionedCall: StatefulPartitionedCall] is not supported\n",
      "ERROR:tf2onnx.tfonnx:Unsupported ops: Counter({'StatefulPartitionedCall': 1})\n"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "\n",
    "tf2onnx.convert.from_function(\n",
    "    model.infer_tf, model.signatures[\"serving_default\"].inputs[:1]\n",
    ")\n",
    "# tf2onnx.convert.from_keras(model, model.signatures[\"serving_default\"], opset=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.infer_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjfmqate6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjfmqate6/assets\n",
      "2024-06-10 11:31:22.370642: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-06-10 11:31:22.370710: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-06-10 11:31:22.372114: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpjfmqate6\n",
      "2024-06-10 11:31:22.411112: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-06-10 11:31:22.411154: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpjfmqate6\n",
      "2024-06-10 11:31:22.484729: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-06-10 11:31:22.523197: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-06-10 11:31:24.002816: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpjfmqate6\n",
      "2024-06-10 11:31:24.487286: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 2115180 microseconds.\n",
      "2024-06-10 11:31:25.069050: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-10 11:31:29.024824: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024895: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024900: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024904: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024908: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024915: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024919: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024923: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024927: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-06-10 11:31:29.024931: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 290, Total Ops 828, % non-converted = 35.02 %\n",
      " * 285 ARITH ops, 5 TF ops\n",
      "\n",
      "- arith.constant:  285 occurrences  (: 1, f32: 244, i32: 40)\n",
      "\n",
      "\n",
      "\n",
      "- tf.EnsureShape:    2 occurrences  (: 1, f32: 1)\n",
      "- tf.StridedSlice:    1 occurrences  (: 1)\n",
      "- tf.Transpose:    2 occurrences  (: 2)\n",
      "  (f32: 65, i32: 2)\n",
      "  (: 1, f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 47)\n",
      "  (f32: 24)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 13)\n",
      "  (f32: 48)\n",
      "  (f32: 92)\n",
      "  (i32: 2)\n",
      "  (i32: 2)\n",
      "  (: 1, f32: 122)\n",
      "\n",
      "  (i32: 20)\n",
      "  (f32: 10)\n",
      "  (: 2, f32: 33)\n",
      "  (: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 5, i32: 1)\n",
      "  (f32: 1, i32: 2)\n",
      "  (f32: 24)\n",
      "  (f32: 8)\n",
      "2024-06-10 11:31:29.186915: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2921] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexEnsureShape, FlexStridedSlice, FlexTranspose\n",
      "Details:\n",
      "\ttf.EnsureShape(tensor<?x?x?xcomplex<f32>>) -> (tensor<?x513x500xcomplex<f32>>) : {device = \"\", shape = #tf_type.shape<?x513x500>}\n",
      "\ttf.EnsureShape(tensor<?x?x?xf32>) -> (tensor<?x1x160xf32>) : {device = \"\", shape = #tf_type.shape<?x1x160>}\n",
      "\ttf.StridedSlice(tensor<?x513x501xcomplex<f32>>, tensor<3xi32>, tensor<3xi32>, tensor<3xi32>) -> (tensor<?x?x?xcomplex<f32>>) : {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 0 : i64}\n",
      "\ttf.Transpose(tensor<?x501x513xcomplex<f32>>, tensor<3xi32>) -> (tensor<?x513x501xcomplex<f32>>) : {device = \"\"}\n",
      "\ttf.Transpose(tensor<?x513x500xcomplex<f32>>, tensor<3xi32>) -> (tensor<?x500x513xcomplex<f32>>) : {device = \"\"}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "from birdclef.label.google_inference import compile_tflite_model\n",
    "\n",
    "tflite_model = compile_tflite_model(model)\n",
    "tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
